{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from random import randint\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from typing import Any, Optional, NamedTuple\n",
    "from string import punctuation\n",
    "from datetime import date\n",
    "from itertools import combinations_with_replacement\n",
    "from collections import Counter, defaultdict\n",
    "from calendar import month_name, month_abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/transaction_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    \n",
    "    def __init__(self, account_category, account_name, description):\n",
    "        \n",
    "        self.account_category: Optional[str] = account_category\n",
    "        self.account_name: Optional[str] = account_name\n",
    "        self.description: Optional[str] = description\n",
    "            \n",
    "        self.docs = defaultdict()\n",
    "        self.labels = defaultdict()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{\"acc.cat:\":<10}{self.account_category}\\n{\"acc.name:\":<10}{self.account_name}\\n{\"desc:\":<10}{self.description}'\n",
    "    \n",
    "    def similarity(self, another_transaction):\n",
    "        \n",
    "        sim_acc_cat = self.docs['account_category'].similarity(another_transaction.docs['account_category'])\n",
    "        sim_acc_name = self.docs['account_name'].similarity(another_transaction.docs['account_name'])\n",
    "        sim_desc = self.docs['description'].similarity(another_transaction.docs['description'])\n",
    "        \n",
    "        print(f'similarity: acc.cat: {sim_acc_cat:.4f} acc.name: {sim_acc_name:.4f} description: {sim_desc:.4f}')\n",
    "        \n",
    "        return (sim_acc_cat, sim_acc_name, sim_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.abbrs = json.load(open('data/acdic.json'))\n",
    "        self.syns = {'revenue': set('revenue unbilled earnings gain income incoming proceeds profit return yield unrealized'.split()),\n",
    "                     'expense': set('expense charge expenditure obligation spending spend overhead surcharge cost'.split()),\n",
    "                     'accrue': set('accrue accumulate amass collect gather aggregate hoard'.split()),\n",
    "                     'consolidation': set('consolidation merger strengthening unification amalgamation'.split()),\n",
    "                     'adjustment': set('adjustment adjust adj alteration correction modification readjustment'.split()),\n",
    "                     'recurring': set('regular periodic monthly weekly fortnightly yearly repeat routine recurring'.split()),\n",
    "                     'defer': set('adjourn delay postpone suspend'.split()),\n",
    "                     'subscription': set('subscription'.split()),\n",
    "                     'payroll': set('payroll salary wages pay remuneration paycheck earning'.split()),\n",
    "                     'liability': set('liability debt burden obligation owing uninvoiced'.split()),\n",
    "                     'rent': set('rent lease rental'.split()),\n",
    "                     'depreciation': set('depreciation devaluation markdown deflation'.split()),\n",
    "                     'tax': set('tax duty levy toll tariff excise'.split()),\n",
    "                     'maintenance': set('maintenance repair'.split()),\n",
    "                     'entertainment': set('entertainment recreation party'.split()),\n",
    "                     'prepaid': set('prepaid'.split()),\n",
    "                     'month': set(map(lambda x: x.lower(), set(month_name[1:]) | set(month_abbr[1:]))),\n",
    "                     'food': set('food meal dinner lunch restaurant cafe brunch breakfast catering wine beer drinks'.split()),\n",
    "                     'reverse': set('reverse back return inverse converse'.split())}\n",
    "        \n",
    "        for k in self.syns:\n",
    "            syns_upd = set()\n",
    "            for w in nlp(' '.join(self.syns[k])):\n",
    "                syns_upd.add(w.lemma_.lower())\n",
    "            self.syns[k] = syns_upd\n",
    "    \n",
    "    def run(self, st):\n",
    "        \n",
    "        _labs = defaultdict(set) \n",
    "        _doc = None\n",
    "        \n",
    "        if (not isinstance(st, str)) or (not st.strip()):\n",
    "            return (_doc, _labs)\n",
    "        \n",
    "        _labs['dates'] = self.find_dates(st)\n",
    "        \n",
    "        st = st.lower().translate({ord(sep): '' for sep in './'})\n",
    "        \n",
    "        st = st.translate(str.maketrans({_: ' ' for _ in punctuation}))\n",
    "        \n",
    "        # unfold abbreviations\n",
    "        st = ' '.join([self.abbrs.get(w, w).lower().replace(',','') for w in st.split()])\n",
    "        \n",
    "        # remove numbers\n",
    "        st = ' '.join([w for w in st.split() if w.isalpha()])\n",
    "        \n",
    "        # remove stopwords\n",
    "        st = ' '.join([w for w in st.split() if w not in STOP_WORDS])\n",
    "        \n",
    "        # replace multiple consecutive white spaces with a single one\n",
    "        st = re.sub(r'\\s+', ' ', st).strip()\n",
    "        \n",
    "        if st:\n",
    "            _doc = nlp(st)\n",
    "        \n",
    "            for what in self.syns:\n",
    "                for w in _doc:\n",
    "                    if w.lemma_ in self.syns[what]:\n",
    "                        _labs['labels'].add(what)\n",
    "            \n",
    "        return (_doc, _labs)\n",
    "    \n",
    "    def find_dates(self, st):\n",
    "        \n",
    "        plausible = dict(day=set(range(1,32)), \n",
    "                         month=set(range(1,13)), \n",
    "                         year=set(range(19,23)) | set(range(2019, 2023)))\n",
    "        \n",
    "        _dates = set()\n",
    "        \n",
    "        # try to create a set of found dates using a single - as separator \n",
    "        try:\n",
    "            _dates |= {re.sub(r'[-\\/.]+','-', d) for d in re.findall(r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{4}\\b|'\n",
    "                                                                     r'\\b\\d{4}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b|'\n",
    "                                                                     r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b', st)}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            _dates |= {d + '-' + str(list(month_abbr).index(m.title())) + '-' + '20' + y \n",
    "                                  for d, m, y in re.findall(r'\\b(\\d{1,2})(' + '|'.join([m for m in month_abbr[1:]]) + r')(\\d{2}\\b)', st, flags=re.IGNORECASE)}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not _dates:\n",
    "            return None\n",
    "        \n",
    "        # dates will be gathered in this set if they are valid\n",
    "        dates = []\n",
    "        \n",
    "        for _date in _dates:\n",
    "            \n",
    "            _date_parts = _date.split('-')\n",
    "            \n",
    "            position_cands = defaultdict(set)\n",
    "            \n",
    "            for i, p in enumerate(_date_parts):\n",
    "                for q in 'year month day'.split():\n",
    "                    if int(p) in plausible[q]:\n",
    "                        position_cands[i].add(q)\n",
    "            \n",
    "            if set(position_cands) != set(range(len(_date_parts))):\n",
    "                continue\n",
    "            \n",
    "            for p0 in position_cands[0]:\n",
    "                for p1 in position_cands[1] - {p0}:\n",
    "                    for p2 in position_cands[2] - {p0} - {p1}:\n",
    "                        \n",
    "                        date_as_dict = {p0: int(_date_parts[0]), p1: int(_date_parts[1]), p2: int(_date_parts[2])}\n",
    "                        \n",
    "                        # make sure year is presented as 20YY\n",
    "                        for _ in date_as_dict:\n",
    "                            if (_ == 'year') and (len(str(date_as_dict[_])) == 2):\n",
    "                                date_as_dict.update({_: int('20'+str(date_as_dict[_]))})\n",
    "                                \n",
    "                        dates.append(date(**date_as_dict))\n",
    "        \n",
    "        \n",
    "\n",
    "        return dates   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run(' ewfefe 2141x !@@@!2 2021--12-4 a.B 3/1452-1-23m  1FEb24  1.1.22 rev accrued maintenance&repairs -- reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = Transaction(**d.iloc[randint(0, len(d)-1)])\n",
    "t2.docs['account_category'], t2.labels['account_category']= p.run(t2.account_category)\n",
    "t2.docs['account_name'], t2.labels['account_name']= p.run(t2.account_name)\n",
    "t2.docs['description'], t2.labels['description']= p.run(t2.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "do = nlp(' ewfefe 2141x !@@@!2 2021--12-4 a.B 3/1452-1-23m  1FEb24  1.1.22 rev accrued maintenance&repairs -- reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_get_array_attrs',\n",
       " '_py_tokens',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "do.user_data.update({'labels': ['maintenance', 'cash']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATE', 'CARDINAL', 'PERSON']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.label_ for t in do.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['maintenance', 'cash']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t2.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.similarity(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans = []\n",
    "\n",
    "for r in d.iterrows():\n",
    "    \n",
    "    t2 = Transaction(**r[1][['account_name', 'account_category','description']])\n",
    "    t2.docs['account_category'], t2.labels['account_category']= p.run(t2.account_category)\n",
    "    t2.docs['account_name'], t2.labels['account_name']= p.run(t2.account_name)\n",
    "    t2.docs['description'], t2.labels['description']= p.run(t2.description)\n",
    "    \n",
    "    for k in t2.labels:\n",
    "        if 'subscription' in t2.labels[k]['labels']:\n",
    "            all_trans.append(r[1])\n",
    "            print(len(all_trans))\n",
    "            \n",
    "    if len(all_trans) == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
