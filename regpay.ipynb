{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from random import randint\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from typing import Any, Optional, NamedTuple\n",
    "from string import punctuation\n",
    "from datetime import date\n",
    "from itertools import combinations_with_replacement\n",
    "from collections import Counter, defaultdict\n",
    "from calendar import month_name, month_abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', \n",
    "                 exclude=['parser', 'ner']  # no need for dependency labels or POS\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/transaction_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component('date_finder')\n",
    "def find_dates(doc):\n",
    "        \n",
    "    plausible = dict(day=set(range(1,32)), \n",
    "                     month=set(range(1,13)), \n",
    "                     year=set(range(19,23)) | set(range(2019, 2023)))\n",
    "    \n",
    "    _dates = set()\n",
    "    \n",
    "    st = ' '.join([t.text for t in doc])\n",
    "    \n",
    "    try:\n",
    "        _dates |= {re.sub(r'[-\\/.]+','-', d) for d in re.findall(r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{4}\\b|'\n",
    "                                                                 r'\\b\\d{4}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b|'\n",
    "                                                                 r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b', st)}\n",
    "        _dates |= {d + '-' + str(list(month_abbr).index(m.title())) + '-' + '20' + y \n",
    "                              for d, m, y in re.findall(r'\\b(\\d{1,2})(' + '|'.join([m for m in month_abbr[1:]]) + r')(\\d{2}\\b)', st, flags=re.IGNORECASE)}\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if not _dates:\n",
    "        return None\n",
    "    \n",
    "    # dates will be gathered in this set if they are valid\n",
    "    dates = []\n",
    "    \n",
    "    for _date in _dates:\n",
    "        \n",
    "        _date_parts = _date.split('-')\n",
    "        \n",
    "        position_cands = defaultdict(set)\n",
    "        \n",
    "        for i, p in enumerate(_date_parts):\n",
    "            for q in 'year month day'.split():\n",
    "                if int(p) in plausible[q]:\n",
    "                    position_cands[i].add(q)\n",
    "        \n",
    "        if set(position_cands) != set(range(len(_date_parts))):\n",
    "            continue\n",
    "        \n",
    "        for p0 in position_cands[0]:\n",
    "            for p1 in position_cands[1] - {p0}:\n",
    "                for p2 in position_cands[2] - {p0} - {p1}:\n",
    "                    \n",
    "                    date_as_dict = {p0: int(_date_parts[0]), p1: int(_date_parts[1]), p2: int(_date_parts[2])}\n",
    "                    \n",
    "                    # make sure year is presented as 20YY\n",
    "                    for _ in date_as_dict:\n",
    "                        if (_ == 'year') and (len(str(date_as_dict[_])) == 2):\n",
    "                            date_as_dict.update({_: int('20'+str(date_as_dict[_]))})\n",
    "                            \n",
    "                    dates.append(date(**date_as_dict))\n",
    "    doc.user_data |= {'dates': dates}\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.find_dates(doc)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('date_finder', name='find_dates', first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    \n",
    "    def __init__(self, account_category, account_name, description):\n",
    "        \n",
    "        self.account_category: Optional[str] = account_category\n",
    "        self.account_name: Optional[str] = account_name\n",
    "        self.description: Optional[str] = description\n",
    "            \n",
    "        self.docs = defaultdict()\n",
    "        self.labels = defaultdict()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{\"acc.cat:\":<10}{self.account_category}\\n{\"acc.name:\":<10}{self.account_name}\\n{\"desc:\":<10}{self.description}'\n",
    "    \n",
    "    def similarity(self, another_transaction):\n",
    "        \n",
    "        sim_acc_cat = self.docs['account_category'].similarity(another_transaction.docs['account_category'])\n",
    "        sim_acc_name = self.docs['account_name'].similarity(another_transaction.docs['account_name'])\n",
    "        sim_desc = self.docs['description'].similarity(another_transaction.docs['description'])\n",
    "        \n",
    "        print(f'similarity: acc.cat: {sim_acc_cat:.4f} acc.name: {sim_acc_name:.4f} description: {sim_desc:.4f}')\n",
    "        \n",
    "        return (sim_acc_cat, sim_acc_name, sim_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.abbrs = json.load(open('data/acdic.json'))\n",
    "        self.syns = {'revenue': set('revenue unbilled earnings gain income incoming proceeds profit return yield unrealized'.split()),\n",
    "                     'expense': set('expense charge expenditure obligation spending spend overhead surcharge cost'.split()),\n",
    "                     'accrue': set('accrue accumulate amass collect gather aggregate hoard'.split()),\n",
    "                     'consolidation': set('consolidation merger strengthening unification amalgamation'.split()),\n",
    "                     'adjustment': set('adjustment adjust adj alteration correction modification readjustment'.split()),\n",
    "                     'recurring': set('regular periodic monthly weekly fortnightly yearly repeat routine recurring'.split()),\n",
    "                     'defer': set('adjourn delay postpone suspend'.split()),\n",
    "                     'subscription': set('subscription'.split()),\n",
    "                     'payroll': set('payroll salary wages pay remuneration paycheck earning'.split()),\n",
    "                     'liability': set('liability debt burden obligation owing uninvoiced'.split()),\n",
    "                     'rent': set('rent lease rental'.split()),\n",
    "                     'depreciation': set('depreciation devaluation markdown deflation'.split()),\n",
    "                     'tax': set('tax duty levy toll tariff excise'.split()),\n",
    "                     'maintenance': set('maintenance repair'.split()),\n",
    "                     'entertainment': set('entertainment recreation party'.split()),\n",
    "                     'prepaid': set('prepaid'.split()),\n",
    "                     'month': set(map(lambda x: x.lower(), set(month_name[1:]) | set(month_abbr[1:]))),\n",
    "                     'food': set('food meal dinner lunch restaurant cafe brunch breakfast catering wine beer drinks'.split()),\n",
    "                     'reverse': set('reverse back return inverse converse'.split())}\n",
    "        \n",
    "        for k in self.syns:\n",
    "            syns_upd = set()\n",
    "            for w in nlp(' '.join(self.syns[k])):\n",
    "                syns_upd.add(w.lemma_.lower())\n",
    "            self.syns[k] = syns_upd\n",
    "    \n",
    "    def run(self, st):\n",
    "        \n",
    "        _labs = defaultdict(set) \n",
    "        _doc = None\n",
    "        \n",
    "        if (not isinstance(st, str)) or (not st.strip()):\n",
    "            return (_doc, _labs)\n",
    "        \n",
    "        _labs['dates'] = self.find_dates(st)\n",
    "        \n",
    "        st = st.lower().translate({ord(sep): '' for sep in './'})\n",
    "        \n",
    "        st = st.translate(str.maketrans({_: ' ' for _ in punctuation}))\n",
    "        \n",
    "        # unfold abbreviations\n",
    "        st = ' '.join([self.abbrs.get(w, w).lower().replace(',','') for w in st.split()])\n",
    "        \n",
    "        # remove numbers\n",
    "        st = ' '.join([w for w in st.split() if w.isalpha()])\n",
    "        \n",
    "        # remove stopwords\n",
    "        st = ' '.join([w for w in st.split() if w not in STOP_WORDS])\n",
    "        \n",
    "        # replace multiple consecutive white spaces with a single one\n",
    "        st = re.sub(r'\\s+', ' ', st).strip()\n",
    "        \n",
    "        if st:\n",
    "            _doc = nlp(st)\n",
    "        \n",
    "            for what in self.syns:\n",
    "                for w in _doc:\n",
    "                    if w.lemma_ in self.syns[what]:\n",
    "                        _labs['labels'].add(what)\n",
    "            \n",
    "        return (_doc, _labs)\n",
    "    \n",
    "    def find_dates(self, st):\n",
    "        \n",
    "        plausible = dict(day=set(range(1,32)), \n",
    "                         month=set(range(1,13)), \n",
    "                         year=set(range(19,23)) | set(range(2019, 2023)))\n",
    "        \n",
    "        _dates = set()\n",
    "        \n",
    "        # try to create a set of found dates using a single - as separator \n",
    "        try:\n",
    "            _dates |= {re.sub(r'[-\\/.]+','-', d) for d in re.findall(r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{4}\\b|'\n",
    "                                                                     r'\\b\\d{4}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b|'\n",
    "                                                                     r'\\b\\d{1,2}[-\\/.]+\\d{1,2}[-\\/.]+\\d{1,2}\\b', st)}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            _dates |= {d + '-' + str(list(month_abbr).index(m.title())) + '-' + '20' + y \n",
    "                                  for d, m, y in re.findall(r'\\b(\\d{1,2})(' + '|'.join([m for m in month_abbr[1:]]) + r')(\\d{2}\\b)', st, flags=re.IGNORECASE)}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not _dates:\n",
    "            return None\n",
    "        \n",
    "        # dates will be gathered in this set if they are valid\n",
    "        dates = []\n",
    "        \n",
    "        for _date in _dates:\n",
    "            \n",
    "            _date_parts = _date.split('-')\n",
    "            \n",
    "            position_cands = defaultdict(set)\n",
    "            \n",
    "            for i, p in enumerate(_date_parts):\n",
    "                for q in 'year month day'.split():\n",
    "                    if int(p) in plausible[q]:\n",
    "                        position_cands[i].add(q)\n",
    "            \n",
    "            if set(position_cands) != set(range(len(_date_parts))):\n",
    "                continue\n",
    "            \n",
    "            for p0 in position_cands[0]:\n",
    "                for p1 in position_cands[1] - {p0}:\n",
    "                    for p2 in position_cands[2] - {p0} - {p1}:\n",
    "                        \n",
    "                        date_as_dict = {p0: int(_date_parts[0]), p1: int(_date_parts[1]), p2: int(_date_parts[2])}\n",
    "                        \n",
    "                        # make sure year is presented as 20YY\n",
    "                        for _ in date_as_dict:\n",
    "                            if (_ == 'year') and (len(str(date_as_dict[_])) == 2):\n",
    "                                date_as_dict.update({_: int('20'+str(date_as_dict[_]))})\n",
    "                                \n",
    "                        dates.append(date(**date_as_dict))\n",
    "        \n",
    "        \n",
    "\n",
    "        return dates   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = {'a':[3,4],'b':2}\n",
    "w2 = {'c': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 |= w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [3, 4], 'b': 2, 'c': 5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run(' ewfefe 2141x !@@@!2 2021--12-4 a.B 3/1452-1-23m  1FEb24  1.1.22 rev accrued maintenance&repairs -- reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = Transaction(**d.iloc[randint(0, len(d)-1)])\n",
    "t2.docs['account_category'], t2.labels['account_category']= p.run(t2.account_category)\n",
    "t2.docs['account_name'], t2.labels['account_name']= p.run(t2.account_name)\n",
    "t2.docs['description'], t2.labels['description']= p.run(t2.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = nlp(' ewfefe 2141x !@@@!2 2021--12-4 a.B 3/1452-1-23m  1FEb24  1.1.22 rev accrued maintenance&repairs -- reversed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'ewfefe',\n",
       " '2141x',\n",
       " '!',\n",
       " '@@@!2',\n",
       " '2021',\n",
       " '-',\n",
       " '-12',\n",
       " '-',\n",
       " '4',\n",
       " 'a.',\n",
       " 'b',\n",
       " '3/1452',\n",
       " '-',\n",
       " '1',\n",
       " '-',\n",
       " '23',\n",
       " 'm',\n",
       " ' ',\n",
       " '1feb24',\n",
       " ' ',\n",
       " '1.1.22',\n",
       " 'rev',\n",
       " 'accrue',\n",
       " 'maintenance&repairs',\n",
       " '--',\n",
       " 'reverse']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.lemma_ for t in do]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('find_dates', <function __main__.find_dates(doc)>),\n",
       " ('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fcf48bb9d60>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fd0101ef0e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fcff5419740>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fcff6968ac0>)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dates': [datetime.date(2022, 1, 1), datetime.date(2022, 1, 1)]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.label_ for t in do.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['maintenance', 'cash']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do.user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t2.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.similarity(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans = []\n",
    "\n",
    "for r in d.iterrows():\n",
    "    \n",
    "    t2 = Transaction(**r[1][['account_name', 'account_category','description']])\n",
    "    t2.docs['account_category'], t2.labels['account_category']= p.run(t2.account_category)\n",
    "    t2.docs['account_name'], t2.labels['account_name']= p.run(t2.account_name)\n",
    "    t2.docs['description'], t2.labels['description']= p.run(t2.description)\n",
    "    \n",
    "    for k in t2.labels:\n",
    "        if 'subscription' in t2.labels[k]['labels']:\n",
    "            all_trans.append(r[1])\n",
    "            print(len(all_trans))\n",
    "            \n",
    "    if len(all_trans) == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
